---
output: 
  pdf_document:
    number_sections: true
    includes:
      in_header: 00_header.tex
fontsize: 12pt
fig_caption: true
geometry: margin=1in
linestretch: 1.5
---

```{r setup, echo=FALSE, message=FALSE}
library(knitr)
library(tidyverse)
library(xtable)
library(MASS)

knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.height = 2)
theme_set(theme_bw(base_family = "serif"))

set.seed(305)
```

\setcounter{section}{5}
\setcounter{subsection}{1}
\setcounter{ex}{16}
\setcounter{df}{11}
\setcounter{page}{24}

## Continuous random variables

It is often convenient to think of a random variable as having a whole (continuous) interval for its set of possible values.

The devices used to describe continuous probability distributions differ from those that describe discrete probability distributions.

Examples of continuous random variables:

\newpage

### Probability density functions and cumulative distribution functions

A *probability density function (pdf)* is the continuous analogue of a discrete random variable's probability mass function (pmf).

\vspace{.1in}
\begin{df}
A \emph{probability density function (pdf)} for a continuous random variable $X$ is a nonnegative function $f(x)$ with
$$
\int\limits_{-\infty}^{\infty} f(x) = 1
$$
and such that for all $a \le b$,
$$
P[a \le X \le b] = \int\limits_a^bf(x)dx.
$$
\end{df}

\vspace{.2in}

1. 
2. 
3. 

\vfill

```{r, fig.height=3}
x <- seq(-5, 22, length.out = 200)
f <- .6*dnorm(x, 3, 2) + .3*dnorm(x, 9, 1) + .1*dnorm(x, 19, .4)
shade <- rbind(data.frame(x = x[x >= 2 & x <= 6], y = f[x >= 2 & x <= 6]),
               data.frame(x = rev(x[x >= 2 & x <= 6]), y = 0))

qplot(x, f, geom = "line") +
  geom_polygon(aes(x, y), data = shade, fill = "blue", alpha = .4) +
  ylab(expression("f(x)"))
```

\newpage

\begin{ex}[Compass needle]
Consider a de-magnetized compass needle mounted at its center so that it can spin freely.  It is spun clockwise and when it comes to rest the angle, $\theta$, from the vertical, is measured. Let 
$$
Y = \text{the angle measured after each spin in radians}
$$

\vspace{.2in}

What values can $Y$ take?

\vspace{.2in}

What form makes sense for $f(y)$?

\vspace{3in}

If this form is adopted, that what must the pdf be?

\newpage

Using this pdf, calculate the following probabilities:

\begin{enumerate}
\itemsep 1.5in 
\item $P[Y < \frac{\pi}{2}]$
\item $P[\frac{\pi}{2} < Y < 2\pi]$
\item $P[\frac{\pi}{6} < Y < \frac{\pi}{4}]$
\item $P[Y = \frac{\pi}{6}]$
\end{enumerate}
\vspace{1in}



\end{ex}

\newpage

\begin{df}
The \emph{cumulative distribution function (cdf)} of a continuous random variable $X$ is a function $F$ such that
$$
F(x) = P[X \le x] = \int\limits_{-\infty}^x f(t) dt
$$
\end{df}

$F(x)$ is obtained from $f(x)$ by integration, and applying the fundamental theorem of calculus yields

$$
\frac{d}{dx}F(x) = f(x).
$$

That is, $f(x)$ is obtained from $F(x)$ by differentiation.

As with discrete random variables, $F$ has the following properties:

\begin{enumerate}
\itemsep 1in
\item
\item
\item
\end{enumerate}

\newpage

\begin{ex}[Compass needle, cont'd]
Recall the compass needle example, with
$$
f(x) = \begin{cases} \frac{1}{2\pi} & 0 \le y \le 2\pi \\ 0 & \text{otherwise}\end{cases}
$$
Find the cdf.

\vspace{.2in}
For $y < 0$

\vspace{1in}
For $0 \le y \le 2\pi$

\vspace{1in}
For $y > 2\pi$
\vfill


\newpage

Calculate the following using the cdf:

$F(1.5)$

\vfill

$P[Y \le \frac{4\pi}{5}]$

\vfill

$P[Y > 5]$

$P[\frac{\pi}{3} < Y \le \frac{\pi}{2}]$

\end{ex}

\newpage

### Quantiles

**Recall:** 

\vspace{.5in}

\begin{df}
The \emph{$p$-quantile of a random variable}, $X$, is the number $Q(p)$ such that $P[X \le Q(p)] = p$.
\end{df}

\vspace{.2in}

In terms of the cumulative distribution function (for a continuous random variable), 

\vspace{1in}

\begin{ex}[Compass needle, cont'd]
Recall the compass needle example, with
$$
f(x) = \begin{cases} \frac{1}{2\pi} & 0 \le y \le 2\pi \\ 0 & \text{otherwise}\end{cases}
$$
$Q(.95)$:

\newpage

You can also calculate quantiles directly from the cdf.

$$
F(x) = \begin{cases} 0 & y < 0 \\
\frac{1}{2\pi}y & 0 \le y \le 2\pi \\ 1 & \text{otherwise}\end{cases}
$$
$Q(.25)$:

\vfill

$Q(.5)$

\vfill

\end{ex}

\newpage

### Means and variances for continuous distributions

It is possible to summarize continuous probability distributions using

1.
2.
3.

\vspace{.2in}

\begin{df}
The \emph{mean} or \emph{expected value} of a continuous random variable $X$ is
$$
\text{E}X = \int\limits_{-\infty}^{\infty} x f(x)dx.
$$
\end{df}

\vspace{.4in}

\begin{ex}[Compass needle, cont'd]
Calculate $\text{E}Y$ where $Y$ is the angle from vertical in radians that a spun needle lands on.

$$
f(y) = \begin{cases} \frac{1}{2\pi} &0 \le y \le 2\pi \\ 0 & \text{otherwise}\end{cases}
$$
\end{ex}

\newpage

\begin{ex}
Calculate $\text{E}X$ where $X$ follows the following distribution

$$
f(x) = \begin{cases} 0 & x < 0 \\ \frac{1}{3}e^{-x/3} & x \ge 0 \end{cases}
$$
\end{ex}
\vspace{5in}

\begin{df}
The \emph{variance} of a continuous random variable $X$ is 

$$
\text{Var} X = \int\limits_{-\infty}^\infty(x - \text{E}X)^2 f(x)dx = \int\limits_{-\infty}^\infty x^2 f(x)dx - (\text{E}X)^2.
$$

The \emph{standard deviation} of $X$ is $\sqrt{\text{Var}X}$.
\end{df}

\newpage

\begin{ex}[Library books]
Let $X$ denote the amount of time for which a book on $2$-hour hold reserve at a college library is checked out by a randomly selected student and suppose its density function is
$$
f(x) = \begin{cases}0.5x & 0 \le x \le 2\\ 0 & \text{otherwise} \end{cases}
$$
Calculate $\text{E}X$ and $\text{Var}X$.
\end{ex}

\newpage

\begin{ex}[Ecology]
An ecologist wishes to mark off a circular sampling region having radius $10$m. However, the radius of the resulting region is actually a random variable $R$ with pdf
$$
f(r) = \begin{cases} \frac{3}{2}(10 - r)^2 & 9 \le r \le 11 \\ 0 & \text{otherwise}\end{cases}
$$
Calculate $\text{E}R$ and $\text{SD}(R)$.
\end{ex}

\newpage

Why does $\text{E}X^2 = \int\limits_{-\infty}^\infty x^2f(x) dx$?
\vspace{5in}

\begin{ex}[Ecology, cont'd]
Calculate the expected \emph{area} of the circular sampling region.

\end{ex}
\newpage

For a linear function, $g(x) = ax + b$, where $a$ and $b$ are constants,

$\text{E}(ax + b)$

\vspace{2.5in}

$\text{Var}(ax + b)$

\vspace{3in}

\begin{ex}[Ecology, cont'd]
Calculate the expected value and variance of the \emph{diameter} of the circular sampling region.
\end{ex}

\newpage

\begin{df}
\emph{Standardization} is the process of transforming a random variable, $X$, into the signed number of standard deviations by which it is is above its mean value.
$$
Z = \frac{X - \text{E}X}{\text{SD}(X)}
$$
\end{df}

\vspace{.2in}

$Z$ has mean $0$

\vfill

$Z$ has variance (and standard deviation) $1$

\vfill


\newpage

### A special continuous distribution

Just as there are a number of useful discrete distributions commonly applied to engineering problems, there are a number of standard continuous probability distributions. 

\vspace{.2in}

\begin{df}
The \emph{exponential$(\alpha)$ distribution} is a continuous probability distribution with probability density function
$$
f(x) = \begin{cases} \frac{1}{\alpha}e^{-x/\alpha} & x > 0 \\ 0 & \text{otherwise}\end{cases}
$$
for $\alpha > 0$.
\end{df}

```{r, fig.height=3}
data.frame(x = seq(0, 5, length.out = 200)) %>%
  mutate(`0.5` = dexp(x, 1/.5),
         `1` = dexp(x, 1),
         `2` = dexp(x, 1/2)) %>%
  gather(alpha, f, -x) %>%
  ggplot() +
  geom_line(aes(x, f, colour = alpha, lty = alpha)) +
  scale_colour_discrete(expression(alpha)) +
  scale_linetype_discrete(expression(alpha)) +
  ylab("f(x)")


```

An $\text{Exp}(\alpha)$ random variable measures the waiting time until a specific event that has an equal chance of happening at any point in time.

Examples: 

\newpage

It is straightforward to show for $X \sim \text{Exp}(\alpha)$, 
\begin{enumerate}
\itemsep .2in
\item $\mu = \text{E}X = \int\limits_{0}^\infty x \frac{1}{\alpha}e^{-x/\alpha} dx = $
\item $\sigma^2 = \text{Var}X = \int\limits_{0}^\infty (x - \alpha)^2 \frac{1}{\alpha}e^{-x/\alpha} dx = $
\end{enumerate}

\vspace{.2in}

Further, $F(x)$ has a simple formulation:



\newpage

\begin{ex}[Library arrivals, cont'd]
Recall the example the arrival rate of students at Parks library between 12:00 and 12:10pm early in the week to be about $12.5$ students per minute. That translates to a $1/12.5 = .08$ minute average waiting time between student arrivals. 

Consider observing the entrance to Parks library at exactly noon next Tuesday and define the random variable

$$
T = \text{the waiting time (min) until the first student passes through the door.}
$$

Using $T \sim \text{Exp}(.08)$, what is the probability of waiting more than $10$ seconds (1/6 min) for the first arrival?

\vfill

What is the probability of waiting less than $5$ seconds?
\vfill

\end{ex}

\newpage
### The Normal distribution

We have already seen the normal distribution as a "bell shaped" distribution, but we can formalize this.

\vspace{.2in}

\begin{df}
The \emph{normal} or \emph{Gaussian}$(\mu, \sigma^2)$ distribution is a continuous probability distribution with probability density
$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} \qquad \text{for all } x
$$
for $\sigma > 0$.
\end{df}

A normal random variable is (often) a finite average of many repeated, independent, identical trials.

\vfill

It is not obvious, but
\begin{enumerate}
\itemsep .5in
\item $\int\limits_{-\infty}^\infty f(x) dx = \int\limits_{-\infty}^\infty \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} dx = $
\item $\text{E}X = \int\limits_{-\infty}^\infty x \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} dx = $
\item $\text{Var}X = \int\limits_{-\infty}^\infty (x - \mu)^2 \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} dx = $
\end{enumerate}


\newpage
The Calculus I methods of evaluating integrals via anti-differentiation will fail when it comes to normal densities. They do not have anti-derivatives that are expressible in terms of elementary functions.

\vspace{.5in}

The use of tables for evaluating normal probabilities depends on the following relationship. If $X \sim \text{Normal}(\mu, \sigma^2)$,
$$
P[a \le X \le b] = \int\limits_a^b\frac{1}{\sqrt{2\pi\sigma^2}} e^{-(x - \mu)^2/{2\sigma^2}}dx = \int\limits_{(a- \mu)/\sigma}^{(b-\mu)/\sigma}\frac{1}{\sqrt{2\pi}} e^{-z^2/2}dz = P\left[\frac{a - \mu}{\sigma} \le Z \le \frac{b - \mu}{\sigma}\right]
$$
where $Z \sim \text{Normal}(0, 1)$.

\vfill

\begin{df}
The normal distribution with $\mu = 0$ and $\sigma = 1$ is called the \emph{standard normal distribution}.
\end{df}

So, we can find probabilities for all normal distributions by tabulating probabilities for only the standard normal distribution. We will use a table of the **standard normal cumulative probability function**.

$$
\Phi(z) = F(z) = \int\limits_{-\infty}^z\frac{1}{\sqrt{2\pi}}e^{-t^2}dt.
$$

\newpage

\begin{ex}[Standard normal probabilities]
$P[Z < 1.76]$
\vfill
$P[.57 < Z < 1.32]$
\vfill
We can also do it in reverse, find $z$ such that $P[-z < Z < z] = .95$.
\end{ex}

\newpage

\begin{ex}[Baby food]
J. Fisher, in his article Computer Assisted Net Weight Control (\emph{Quality Progress}, June 1983), discusses the filling of food containers with strained plums and tapioca by weight. The mean of the values portrayed is about $137.2$g, the standard deviation is about $1.6$g, and data look bell-shaped. Let 
$$
W = \text{the next fill weight.}
$$

\vspace{.5in}

Let's find the probability that the next jar contains less food by mass than it's supposed to (declared weight = $135.05$g).

\vspace{3in}

\includegraphics{images/head_normal_cdf.png}
\end{ex}

\newpage

\begin{ex}[More normal probabilities]
Using the standard normal table, calculate the following:

$P(X \le 3), X \sim \text{Normal}(2, 64)$
\vfill
$P(X > 7), X \sim \text{Normal}(6, 9)$
\vfill
$P(|X - 1| > 0.5), X \sim \text{Normal}(2, 4)$
\vfill
\end{ex}

\newpage
We can find standard normal quantiles by using the standard normal table in reverse.

\begin{ex}[Baby food, cont'd]
For the jar weights $X \sim \text{Normal}(137.2, 1.62^2)$, find $Q(0.1)$.
\vfill
\includegraphics{images/head_normal_cdf.png}
\end{ex}
\newpage

\begin{ex}[Normal quantiles]
Find:


$Q(0.95)$ of $X \sim \text{Normal}(9, 3)$ .
\vfill

$c$ such that $P(|X - 2| > c) = 0.01$, $X \sim \text{Normal}(2, 4)$ 
\vfill

\end{ex}

\newpage

\includepdf[pages=-]{../../tables/standard-normal.pdf}
