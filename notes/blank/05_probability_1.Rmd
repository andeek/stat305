---
output: 
  pdf_document:
    number_sections: true
    includes:
      in_header: 00_header.tex
fontsize: 12pt
fig_caption: true
geometry: margin=1in
linestretch: 1.5
---

```{r setup, echo=FALSE, message=FALSE}
library(knitr)
library(tidyverse)
library(xtable)
library(MASS)

knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.height = 2)
theme_set(theme_bw(base_family = "serif"))

set.seed(305)
```

\setcounter{section}{4}

# Probability: the mathematics of randomness

The theory of probability is the mathematician's description of random variation. This chapter introduces enough probability to serve as a minimum background for making formal statistical inferences.

\vspace{2in}

## (Discrete) random variables

The concept of a random variable is introduced in general terms and the special case of discrete data is considered.

\vspace{1in}

### Random variables and distributions

It is helpful to think of data values as subject to chance influences. Chance is commonly introduced into the data collection process through 

1. 
2.
3.

\vspace{.1in}
\begin{df}
A \emph{random variable} is a quantity that (prior to observation) can be thought of as dependent on chance phenomena.
\end{df}

\vspace{2in}

\begin{df}
A \emph{discrete random variable} is one that has isolated or separated possible values (rather than a continuum of available outcomes).
\end{df}

\vspace{.1in}

\begin{df}
A \emph{continuous random variable} is one that can be idealized as having an entire (continuous) interval of numbers as its set of values.
\end{df}

\vspace{1in}

\begin{ex}[Roll of a die]

\end{ex}
\newpage

\begin{df}
To specify a \emph{probability distribution} for a random variable is to give its set of possible values and (in one way or another) consistently assign numbers between $0$ and $1$ - called \emph{probabilities} - as measures of the likelihood that the various numerical values will occur
\end{df}

\begin{ex}[Roll of a die, cont'd]

\end{ex}
\vspace{3in}

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c }
$x$ & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
$P[X = x]$ & $1/6$ & $1/6$ & $1/6$ & $1/6$ & $1/6$ & $1/6$
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c }
$y$ & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
$P[Y = y]$ & $5/22$ & $7/44$ & $1/22$ & $7/44$ & $2/11$ & $5/22$
\end{tabular}
\end{table}

```{r, fig.show='hold', fig.width=3}
x <- rep(1/6, 6)
y <- c(5/22, 7/44, 1/22, 7/44, 2/11, 5/22)

ggplot() +
  geom_bar(aes(factor(1:6), x), stat = "identity") +
  xlab("x") + ylab("P[X = x]")

ggplot() +
  geom_bar(aes(factor(1:6), y), stat = "identity") +
  xlab("y") + ylab("P[Y = y]")
```

\newpage

\begin{ex}[Shark attacks]
Suppose $S$ is the number of provoked shark attacks off FL next year. This has an infinite number of possible values. Here is one possible (made up) distribution:
\end{ex}

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c}
$s$ & 1 & 2 & 3 & $\cdots$ & k & $\cdots$ \\
\hline
$P[S = s]$ & $\frac{6}{\pi^2}$ & $\frac{1}{2^2}\frac{6}{\pi^2}$ & $\frac{1}{3^2}\frac{6}{\pi^2}$ & $\cdots$ & $\frac{1}{k^2}\frac{6}{\pi^2}$ & $\cdots$
\end{tabular}
\end{table}


```{r}
s <- 1/(1:10)^2*(6/pi^2)
ggplot() +
  geom_bar(aes(factor(1:10), s), stat = "identity") +
  xlab("s") + ylab("P[S = s]")
```

\vspace{1in}



### Probability mass functions and cumulative distribution functions

The tool most often used to describe a discrete probability distribution is the *probability mass function*.

\vspace{.1in}
\begin{df}
A \emph{probability mass function (pmf)} for a discrete random variable $X$, having possible values $x_1, x_2, \dots$, is a nonnegative function $f(x)$ with $f(x_1) = P[X = x_1]$, the probability that $X$ takes the value $x_1$.
\end{df}

\newpage

Properties of a mathematically valid probability mass function:

\begin{enumerate}
\itemsep .2in
\item 
\item
\end{enumerate}

\vspace{.2in}
A probability mass function $f(x)$ gives probabilities of occurence for individual values. Adding the appropriate values gives probabilities associated with the occurence of multiple values.
\vspace{.2in}

\begin{ex}[Torque]
Let $Z = $ the torque, rounded to the nearest integer, required to loosen the next bolt on an apparatus.

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c c c c c }
$z$ & $11$ & $12$ & $13$ & $14$ & $15$ & $16$ & $17$ & $18$ & $19$ & $20$ \\
\hline
$f(z)$ & $0.03$ & $0.03$ & $0.03$ & $0.06$ & $0.26$ & $0.09$ & $0.12$ & $0.20$ & $0.15$ & $0.03$
\end{tabular}
\end{table}

Calculate the following probabilities:

\vspace{.2in}

\begin{itemize}
\itemsep .7in
\item[] $P(Z \le 14)$
\item[] $P(Z > 16)$
\item[] $P(Z \text{ is even})$
\item[] $P(Z \text{ in } \{15, 16, 18\})$
\end{itemize}
\end{ex}

\newpage

Another way of specifying a discrete probability distribution is sometimes used.

\vspace{.2in}
\begin{df}
The \emph{cumulative probability distribution (cdf)} for a random variable $X$ is a function $F(x)$ that for each number $x$ gives the probability that $X$ takes that value or a smaller one, $F(x) = P[X \le x]$.
\end{df}
\vspace{.2in}

Since (for discrete distributions) probabilities are calculated by summing values of $f(x)$,

$$
F(x) = P[X \le x] = \sum\limits_{y \le x} f(y)
$$

\vspace{.2in}

Properties of a mathematically valid cumulative distribution function:

\begin{enumerate}
\itemsep .2in
\item 
\item
\item
\item
\end{enumerate}

\newpage

\begin{ex}[Torque, cont'd]

Let $Z = $ the torque, rounded to the nearest integer, required to loosen the next bolt on an apparatus.

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c c c c c }
$z$ & $11$ & $12$ & $13$ & $14$ & $15$ & $16$ & $17$ & $18$ & $19$ & $20$ \\
\hline
$F(z)$ & $0.03$ & $0.06$ & $0.09$ & $0.15$ & $0.41$ & $0.50$ & $0.62$ & $0.82$ & $0.97$ & $1$
\end{tabular}
\end{table}

```{r torque_cdf, fig.show='hide', results='asis'}
z <- 10:20
F_z <- c(0, 0.03, 0.06, 0.09, 0.15, 0.41, 0.50, 0.62, 0.82, 0.97, 1)

ggplot() +
  geom_segment(aes(x = z, xend = z + 1), y = F_z, yend = F_z) +
  geom_point(aes(z[-1], F_z[-1])) +
  geom_point(aes(z[-length(z)] + 1, F_z[-length(F_z)]), pch = 1) +
  ylab(expression("F(z)"))
```
\begin{figure}[H]
\centering
\includegraphics{05_probability_1_files/figure-latex/torque_cdf-1.pdf}
\caption{Cdf function for torques.}
\end{figure}

Calculate the following probabilities using the {\bf cdf only}:

\vspace{.1in}

\begin{itemize}
\itemsep .7in
\item[] $F(10.7)$
\item[] $P(Z \le 15.5)$
\item[] $P(12.1 < Z \le 14)$
\item[] $P(15 \le Z < 18)$
\end{itemize}
\end{ex}

\newpage

\begin{ex}
Say we have a random variable $Q$ with pmf:

\begin{table}[H]
\centering
\begin{tabular}{c c}
$q$ & $f(q)$ \\
\hline
$1$ & $0.34$ \\
$2$ & $0.1$ \\
$3$ & $0.22$ \\
$7$ & $0.34$
\end{tabular}
\end{table}

Draw the cdf.
\end{ex}
\newpage

### Summaries

Almost all of the devices for describing relative frequency (empirical) distributions in Ch. 3 have versions that can describe (theoretical) probability distributions.

1. 
2. 
3.

\vspace{.5in}

\begin{df}
The \emph{mean} or \emph{expected value} of a discrete random variable $X$ is

$$
\text{E}X = \sum\limits_x xf(x)
$$
\end{df}

\newpage

\begin{ex}[Roll of a die, cont'd]

Calculate the expected value of a toss of a fair and unfair die.

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c }
$x$ & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
$P[X = x]$ & $1/6$ & $1/6$ & $1/6$ & $1/6$ & $1/6$ & $1/6$
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c }
$y$ & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
$P[Y = y]$ & $5/22$ & $7/44$ & $1/22$ & $7/44$ & $2/11$ & $5/22$
\end{tabular}
\end{table}
\end{ex}

\newpage

\begin{ex}[Torque, cont'd]
Let $Z = $ the torque, rounded to the nearest integer, required to loosen the next bolt on an apparatus.

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c c c c c c }
$z$ & $11$ & $12$ & $13$ & $14$ & $15$ & $16$ & $17$ & $18$ & $19$ & $20$ \\
\hline
$f(z)$ & $0.03$ & $0.03$ & $0.03$ & $0.06$ & $0.26$ & $0.09$ & $0.12$ & $0.20$ & $0.15$ & $0.03$
\end{tabular}
\end{table}

Calculate the expected torque required to loosen the next bolt.
\end{ex}

\vspace{3in}

\begin{df}
The \emph{variance} of a discrete random variable $X$ is
$$
\text{Var}X = \sum\limits_x(x - \text{E}X)^2f(x) = \sum\limits_x x^2f(x) - (\text{E}X)^2.
$$
The \emph{standard deviation} of $X$ is $\sqrt{\text{Var}X}$. 
\end{df}
\newpage

\begin{ex}
Say we have a random variable $Q$ with pmf:

\begin{table}[H]
\centering
\begin{tabular}{c c}
$q$ & $f(q)$ \\
\hline
$1$ & $0.34$ \\
$2$ & $0.1$ \\
$3$ & $0.22$ \\
$7$ & $0.34$
\end{tabular}
\end{table}

Calculate the variance and the standard deviation.
\end{ex}

\newpage

\begin{ex}[Roll of a die, cont'd]
Calculate the variance and standard deviation of a roll of a fair die.
\end{ex}

\vspace{4in}

### Special discrete distributions

